{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65ac7f9f-0e40-4074-9b2b-c90a2641c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, make_response, jsonify, request, render_template\n",
    "from datetime import  datetime, date,timedelta\n",
    "import yfinance as yf\n",
    "from code_cr import *\n",
    "from pykrx import stock\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "#                      데이터\n",
    "# ====================================================\n",
    "com_df=pd.read_csv('com_df.csv',\n",
    "                   dtype={'stock_code': 'str', '표준코드': 'str', '단축코드': 'str', 'stock_code_ori':'str'},\n",
    "                   parse_dates=['listed_date', '상장일'])\n",
    "\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "#                      라우터\n",
    "# ====================================================\n",
    "app = Flask(__name__, template_folder=\"template\", static_folder=\"static\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79423229-665e-4c91-b021-5fae5466a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests   #웹통신\n",
    "import json\n",
    "from pmdarima.arima import ndiffs\n",
    "import pmdarima as pm\n",
    "from pykrx import stock\n",
    "\n",
    "#                   ==============\n",
    "#                      업종 분류\n",
    "#                   ==============\n",
    "# -------- 동일 업종 기업 출력\n",
    "# TODO(미완성) 동일 업종 선택\n",
    "def select_same_industry(corp_name):\n",
    "    indus=com_df[com_df['nm']==corp_name]['industry'].values[0] # TODO(df 확인)\n",
    "\n",
    "    # print(com_df.groupby(by='industry')['nm'].nunique().max()) # 동종업계 최대 151개 -> 151개 재무제표 크롤링?\n",
    "\n",
    "    list_com=com_df[com_df['industry']==indus]['corp_name'].values.tolist()\n",
    "    return list_com\n",
    "\n",
    "\n",
    "\n",
    "#  -------- 네이버증권 연관기업 코드(hjh)\n",
    "def relate_code_crawl(co):\n",
    "    #연관 종목코드 있는 페이지 불러오기\n",
    "    url='https://finance.naver.com/item/main.naver?code='+str(co)\n",
    "    page=pd.read_html(url,encoding='CP949')\n",
    "    #연관 종목명과 종목코드 뽑아내기(code_list[0]은 '종목명'이어서 제외)\n",
    "    code_list=page[4].columns.tolist()\n",
    "    code_list=code_list[1:]\n",
    "    #종목코드 리스트 반환\n",
    "    codes=[]\n",
    "    for word in (code_list):\n",
    "        codes.append(word[-6:])\n",
    "    #print(codes)\n",
    "    return codes\n",
    "\n",
    "#relate_code_crawl('000660')\n",
    "\n",
    "\n",
    "\n",
    "#                   ==============\n",
    "#                  기업 이름 코드 변환\n",
    "#                   ==============\n",
    "\n",
    "# -------- 네이버 재무제표 크롤링 용 gicode로 변환\n",
    "def nm_to_bs_gicode(corp_name):\n",
    "    gi=com_df[com_df['nm']==corp_name]['cd']\n",
    "    gi=gi.values[0]\n",
    "    return gi\n",
    "\n",
    "\n",
    "\n",
    "def stc_code_to_bs_gicode(stock_code):\n",
    "    gi = com_df[com_df['stock_code'] == stock_code]['cd']\n",
    "    gi = gi.values[0]\n",
    "    return gi\n",
    "\n",
    "\n",
    "\n",
    "def yh_code_to_bs_gicode(yh_code):\n",
    "    gi = com_df[com_df['yh_code'] == yhcode]['cd']\n",
    "    gi = gi.values[0]\n",
    "    return gi\n",
    "\n",
    "\n",
    "\n",
    "# -------- 네이버 금융 크롤링 용 gicode로 변환\n",
    "def nm_to_fn_gicode(corp_name):\n",
    "    gi=com_df[com_df['nm']==corp_name]['stock_code']\n",
    "    gi=gi.values[0]\n",
    "    return gi\n",
    "\n",
    "\n",
    "\n",
    "def yh_code_to_fn_gicode(yh_code):\n",
    "    gi=com_df[com_df['yh_code']==yh_code]['stock_code']\n",
    "    gi=gi.values[0]\n",
    "    return gi\n",
    "\n",
    "\n",
    "\n",
    "# -------- 코드를 기업이름으로 변환\n",
    "def stc_code_to_nm(stock_code):\n",
    "    gi = com_df[com_df['stock_code'] == stock_code]['nm']\n",
    "    gi = gi.values[0]\n",
    "    return gi\n",
    "\n",
    "\n",
    "\n",
    "def yh_code_to_nm(yh_code):\n",
    "    gi = com_df[com_df['yh_code'] == yh_code]['nm']\n",
    "    gi = gi.values[0]\n",
    "    return gi\n",
    "\n",
    "\n",
    "\n",
    "#                   ==============\n",
    "#                     데이터 수집\n",
    "#                   ==============\n",
    "\n",
    "\n",
    "# -------- Balance Sheets API call\n",
    "# def bs_api(corp_name=None, yh_code=None, stock_code=None):\n",
    "#     print('haha')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------- Balance Sheets Crawling(재무제표 크롤링)\n",
    "# 220220 수정\n",
    "# 1) 매개변수 stock_code로 축약\n",
    "# 2) kind로 특정 테이블 지정하는 대신 데이터프레임 리스트 전체 반환\n",
    "# 3) '~계산에 참여한 계정 펼치기' 제거는 선택사항으로 둠\n",
    "\n",
    "def bs_craw(stock_code, clear_name=False):  # ------- 검색과 연동해서 입력 변수 설정\n",
    "    \"\"\"\n",
    "    # kind\n",
    "        : 0 (연간 포괄손익계산서),  1 (분기별 포괄손익계산서)\n",
    "          2 (연간 재무상태표),     3 (분기별 재무상태표)\n",
    "          4 (연간 현금흐름표),     5 (분기별 현금프름표)\n",
    "    \"\"\"\n",
    "\n",
    "    # ------- 검색과 연동해서 입력되는 변수 따라 gicode(네이버에서 분류하는 기업 코드)로 변환\n",
    "    gcode = stc_code_to_bs_gicode(stock_code)\n",
    "\n",
    "    url = f\"http://comp.fnguide.com/SVO2/ASP/SVD_Finance.asp?NewMenuID=103&gicode={gcode}\"\n",
    "\n",
    "    table_list = pd.read_html(url, encoding='UTF-8')\n",
    "\n",
    "    # 항목에서 불필요한 부분 제거('계산에 참여한 계정 펼치기')\n",
    "    if clear_name == False:\n",
    "        return table_list\n",
    "\n",
    "    else:\n",
    "        new_table_list = []\n",
    "        for tbl in table_list:\n",
    "            for i, idx in enumerate(tbl.iloc[:, 0]):\n",
    "                m = idx.replace('계산에 참여한 계정 펼치기', '')\n",
    "                tbl.iloc[i, 0] = m\n",
    "            new_table_list.append(tbl)\n",
    "        return new_table_list\n",
    "\n",
    "\n",
    "# ------- 네이버 금융\n",
    "# 220220 수정\n",
    "# 1) 매개변수 stock_code로 축약\n",
    "# 2) kind로 특정 테이블 지정하는 대신 데이터프레임 리스트 전체 반환\n",
    "def fn_craw(stock_code):\n",
    "    \"\"\"\n",
    "       # kind\n",
    "           : 0 (전일&당일 상한가, 하한가, 거래량 등) #TODO 가공 필요\n",
    "             1 (증권사 별 매도 매수 정보) #TODO 가공 필요(컬럼이름)\n",
    "             2 (외국인, 기관 거래 정보) #TODO 가공 필요\n",
    "             3 (기업실적분석(연도별 분기별 주요재무 정보)) #TODO 가공 필요?\n",
    "             4 (동일업종비교) #TODO 가공 필요?\n",
    "             5 (시가총액, 주식수, 액면가 정보) #TODO 가공 필요\n",
    "             6 (외국인 주식 한도, 보유 정보)\n",
    "             7 (목표주가 정보) #TODO 가공 필요\n",
    "             8 (PER, PBR 배당수익률 정보) (주가 따라 변동) #TODO 가공 필요\n",
    "             9 (동일업종 PER, 등락률 정보) #TODO 가공 필요\n",
    "             10 (호가 10단계)\n",
    "             11 (인기 검색 종목: 코스피) #TODO 가공 필요\n",
    "             12 (인기 검색 종목: 코스닥) #TODO 가공 필요\n",
    "       \"\"\"\n",
    "\n",
    "    gcode = str(stock_code)\n",
    "\n",
    "    url = f\"https://finance.naver.com/item/main.naver?code={gcode}\"\n",
    "    table_list = pd.read_html(url, encoding='euc-kr')\n",
    "\n",
    "    return table_list\n",
    "\n",
    "#                   ==============\n",
    "#                      지표 선정\n",
    "#                   ==============\n",
    "\n",
    "# 220222 날씨 수정 시작 ---------------------------------------------\n",
    "\n",
    "# -------- 지표 선정\n",
    "# 220220 수정\n",
    "# 1) 매개변수 stock_code로 축약\n",
    "# 2) 데이터프레임 하나가 아닌 리스트로 받아오기때문에 kind 제거하고 직접 선택해줌\n",
    "# 3) sli_df_y, sil_df_q 에서 '-' 가공 시 if 조건에 따라 처리하는 대신 lambda와 re.sub 이용\n",
    "# 4) dict 대신 array로 반환, 기업 이름(nm도 반환)\n",
    "def idv_radar_weather_data(stock_code):\n",
    "    \"\"\"\n",
    "    # <지표 설명>\n",
    "    # 1. 배당 분석                      -> 배당성향(배당 커버리지의 역수.)\n",
    "    # 2. 유동성 분석(단기채무지급능력)    -> 당좌비율(당좌자산 / 유동부채)\n",
    "    # 3. 재무건전성 분석(레버리지 비율)   -> 부채비율(총부채 / 자기자본)의 역수\n",
    "    # 4. 수익성분석                      -> 매출수익성(당기순이익/매출액))\n",
    "    # 5. 성장성분석                      -> 순이익성장률\n",
    "    \"\"\"\n",
    "\n",
    "    gcode = stock_code\n",
    "    nm = stc_code_to_nm(stock_code)\n",
    "\n",
    "    sil_df = fn_craw(gcode)[3]  # 3: 기업실적정보 재무제표 (220220 수정)\n",
    "    foreign_ms = fn_craw(gcode)[2].loc[1, '외국인']  # 2 : 외국인, 기관 거래 정보\n",
    "    giguan_ms = fn_craw(gcode)[2].loc[1, '기관']  # 2 : 외국인, 기관 거래 정보\n",
    "\n",
    "    if (sil_df.iloc[0:8, 3].isna().sum()) > 0:  # 표 안 가르고 계산하는 건 신규 상장 기업은 정보가 아예 없기 때문\n",
    "        pass\n",
    "    elif (sil_df.iloc[0:8, 9].isna().sum()) > 0:  # 표 안 가르고 계산하는 건 신규 상장 기업은 정보가 아예 없기 때문\n",
    "        pass\n",
    "\n",
    "\n",
    "    else:\n",
    "        # 0. 재무정보는 최신 분기 실공시 기준\n",
    "        # 0. 단, 배당은 1년에 한 번 이루어지기 때문에 최신 년도 공시 기준임\n",
    "        sil_df_y = sil_df['최근 연간 실적'].iloc[:, 2]  # 느리지만 .iloc으로 하는 이유는 공시 날짜가 다른 기업이 있기 때문\n",
    "        sil_df_q = sil_df['최근 분기 실적'].iloc[:, 4]\n",
    "\n",
    "        sil_df_y = sil_df_y.fillna(0)\n",
    "        sil_df_q = sil_df_q.fillna(0)\n",
    "\n",
    "        if sil_df_y.dtype == 'O':\n",
    "            sil_df_y = sil_df_y.apply(lambda x: re.sub('^-$', '0', '{}'.format(x)))\n",
    "            sil_df_y = sil_df_y.astype('float')\n",
    "\n",
    "        if sil_df_q.dtype == 'O':\n",
    "            sil_df_q = sil_df_q.apply(lambda x: re.sub('^-$', '0', '{}'.format(x)))\n",
    "            sil_df_q = sil_df_q.astype('float')\n",
    "\n",
    "        # 1. 배당성향(bd_tend)\n",
    "        bd_tend = sil_df_y[15]  # 실제 배당 성향\n",
    "\n",
    "        # 2. 유동성 분석 - 당좌비율(당좌자산/유동부채)\n",
    "        #                       당좌자산 = (유동자산 - 재고자산)\n",
    "        dj_rate = sil_df_q[7]  # 당좌비율\n",
    "\n",
    "        # 3. 재무건전성 분석 - 부채비율(총부채/자기자본)의 역수\n",
    "        bch_rate = sil_df_q[6] / 100  # 부채비율\n",
    "        bch_rate = round((1 / bch_rate) * 100, 2)\n",
    "\n",
    "        # 4. 수익성 분석 - 매출수익성(당기순이익/매출액) # TODO 매출액 0인 애들은?\n",
    "\n",
    "        dg_bene = sil_df_q[2]\n",
    "        mch = sil_df_q[0]\n",
    "\n",
    "        suyk = round((dg_bene / mch) * 100, 2)\n",
    "\n",
    "        # 5. 성장성 분석 - 순이익성장률(지속성장 가능률)\n",
    "        # (1-배당성향)*자기자본순이익률(ROE)\n",
    "        #    유보율\n",
    "\n",
    "        roe = sil_df_y[5] / 100\n",
    "        ubo = (100 - bd_tend) / 100\n",
    "        grth = round(roe * ubo * 100, 2)\n",
    "\n",
    "        data_arr = np.array([bd_tend, dj_rate, bch_rate, suyk, grth])\n",
    "\n",
    "        # weather part----------------\n",
    "        # PER?\n",
    "        weather_per = sil_df_y[10]\n",
    "\n",
    "        # PBR\n",
    "        weather_pbr = sil_df_y[12]\n",
    "\n",
    "        # ROE\n",
    "        weather_roe = sil_df_y[5]\n",
    "\n",
    "        # EPS\n",
    "        weather_eps = sil_df_y[9]\n",
    "\n",
    "        # BPS\n",
    "        weather_bps = sil_df_y[11]\n",
    "\n",
    "        # array\n",
    "        weather_arr = np.array([weather_per, weather_pbr, weather_roe, weather_eps, weather_bps])\n",
    "\n",
    "        return data_arr, weather_arr, nm, foreign_ms, giguan_ms\n",
    "\n",
    "# 수정수정수정\n",
    "\n",
    "# -------- 관련 기업 지표 선정(상대적 비율 기준)\n",
    "# 220220 수정\n",
    "# 1) 매개변수 stock_code로 축약\n",
    "# 2) dict 대신 array로 반환, 기업 이름(nm도 반환)\n",
    "\n",
    "# 220222 날씨\n",
    "\n",
    "def relate_radar_weather_data(stock_code):\n",
    "    label_list = ['배당성향', '유동성', '건전성', '수익성', '성장성']\n",
    "    arr_list = []\n",
    "\n",
    "    # 주식 코드,이름으로 변환\n",
    "\n",
    "    gcode = stock_code\n",
    "\n",
    "    relate_corp = relate_code_crawl(co=gcode)\n",
    "\n",
    "    # 다섯 개 회사가 안에 있다\n",
    "    arr_list = [idv_radar_weather_data(stock_code=stcd) for stcd in relate_corp]\n",
    "\n",
    "    # arr_list에서 데이터 분리\n",
    "    radar_list = [x[0] for x in arr_list if x is not None]\n",
    "    weather_list = [x[1] for x in arr_list if x is not None]\n",
    "    nm_list = [x[2] for x in arr_list if x is not None]\n",
    "\n",
    "    # 외인 매수, 기관 매수\n",
    "    try:\n",
    "        foreign_ms = arr_list[0][3]\n",
    "    except TypeError:\n",
    "        foreign_ms=0.01\n",
    "\n",
    "    try:\n",
    "        giguan_ms = arr_list[0][4]\n",
    "    except TypeError:\n",
    "        giguan_ms=0.01\n",
    "\n",
    "    # radar_chart_data\n",
    "    radar_list = np.array(radar_list)\n",
    "\n",
    "    radar_list[:, 0] = (radar_list[:, 0] / radar_list[:, 0].mean()) * 100\n",
    "    radar_list[:, 1] = (radar_list[:, 1] / radar_list[:, 1].mean()) * 100\n",
    "    radar_list[:, 2] = (radar_list[:, 2] / radar_list[:, 2].mean()) * 100\n",
    "    radar_list[:, 3] = (radar_list[:, 3] / radar_list[:, 3].mean()) * 100\n",
    "    radar_list[:, 4] = (radar_list[:, 4] / radar_list[:, 4].mean()) * 100\n",
    "\n",
    "    # radar_chart_dict\n",
    "    radar_dict_list = []\n",
    "\n",
    "    for i, nm in enumerate(nm_list):\n",
    "        dic = {}\n",
    "        dic[nm] = radar_list[i, :].tolist()\n",
    "        radar_dict_list.append(dic)\n",
    "\n",
    "    # weather_chart_data\n",
    "    weather_list = np.array(weather_list)\n",
    "\n",
    "    weather_list[:, 0] = (weather_list[:, 0] / weather_list[:, 0].mean())  # 각 기업의 평균 대비 PER\n",
    "    weather_list[:, 1] = (weather_list[:, 1] / weather_list[:, 1].mean())  # 각 기업의 평균 대비 PBR\n",
    "    weather_list[:, 2] = (weather_list[:, 2] / weather_list[:, 2].mean())  # 각 기업의 평균 대비 ROE\n",
    "    weather_list[:, 3] = (weather_list[:, 3] / weather_list[:, 3].mean())  # 각 기업의 평균 대비 EPS\n",
    "    weather_list[:, 4] = (weather_list[:, 4] / weather_list[:, 4].mean())  # 각 기업의 평균 대비 BPS\n",
    "    weather_list=np.round(weather_list, 2)\n",
    "\n",
    "    return label_list, radar_dict_list, weather_list[0], foreign_ms, giguan_ms\n",
    "\n",
    "\n",
    "# 220222 날씨 수정 끝 ---------------------------------------------\n",
    "\n",
    "#                   ==============\n",
    "#                      지표 선정\n",
    "#                   ==============\n",
    "\n",
    "# -------- 지표 선정\n",
    "# 220220 수정\n",
    "# 1) 매개변수 stock_code로 축약\n",
    "# 2) 데이터프레임 하나가 아닌 리스트로 받아오기때문에 kind 제거하고 직접 선택해줌\n",
    "# 3) sli_df_y, sil_df_q 에서 '-' 가공 시 if 조건에 따라 처리하는 대신 lambda와 re.sub 이용\n",
    "# 4) dict 대신 array로 반환, 기업 이름(nm도 반환)\n",
    "def idv_radar_data(stock_code):\n",
    "    \"\"\"\n",
    "    # <지표 설명>\n",
    "    # 1. 배당 분석                      -> 배당성향(배당 커버리지의 역수.)\n",
    "    # 2. 유동성 분석(단기채무지급능력)    -> 당좌비율(당좌자산 / 유동부채)\n",
    "    # 3. 재무건전성 분석(레버리지 비율)   -> 부채비율(총부채 / 자기자본)의 역수\n",
    "    # 4. 수익성분석                      -> 매출수익성(당기순이익/매출액))\n",
    "    # 5. 성장성분석                      -> 순이익성장률\n",
    "    \"\"\"\n",
    "\n",
    "    gcode = stock_code\n",
    "    nm = stc_code_to_nm(stock_code)\n",
    "\n",
    "    sil_df = fn_craw(gcode)[3]  # 3: 기업실적정보 재무제표 (220220 수정)\n",
    "\n",
    "    if (sil_df.iloc[0:8, 3].isna().sum()) > 0:  # 표 안 가르고 계산하는 건 신규 상장 기업은 정보가 아예 없기 때문\n",
    "        pass\n",
    "    elif (sil_df.iloc[0:8, 9].isna().sum()) > 0:  # 표 안 가르고 계산하는 건 신규 상장 기업은 정보가 아예 없기 때문\n",
    "        pass\n",
    "\n",
    "\n",
    "    else:\n",
    "        # 0. 재무정보는 최신 분기 실공시 기준\n",
    "        # 0. 단, 배당은 1년에 한 번 이루어지기 때문에 최신 년도 공시 기준임\n",
    "        sil_df_y = sil_df['최근 연간 실적'].iloc[:, 2]  # 느리지만 .iloc으로 하는 이유는 공시 날짜가 다른 기업이 있기 때문\n",
    "        sil_df_q = sil_df['최근 분기 실적'].iloc[:, 4]\n",
    "\n",
    "        sil_df_y = sil_df_y.fillna(0)\n",
    "        sil_df_q = sil_df_q.fillna(0)\n",
    "\n",
    "        if sil_df_y.dtype == 'O':\n",
    "            sil_df_y = sil_df_y.apply(lambda x: re.sub('^-$', '0', '{}'.format(x)))\n",
    "            sil_df_y = sil_df_y.astype('float')\n",
    "\n",
    "        if sil_df_q.dtype == 'O':\n",
    "            sil_df_q = sil_df_q.apply(lambda x: re.sub('^-$', '0', '{}'.format(x)))\n",
    "            sil_df_q = sil_df_q.astype('float')\n",
    "\n",
    "        # 1. 배당성향(bd_tend)\n",
    "        bd_tend = sil_df_y[15]  # 실제 배당 성향\n",
    "\n",
    "        # 2. 유동성 분석 - 당좌비율(당좌자산/유동부채)\n",
    "        #                       당좌자산 = (유동자산 - 재고자산)\n",
    "        dj_rate = sil_df_q[7]  # 당좌비율\n",
    "\n",
    "        # 3. 재무건전성 분석 - 부채비율(총부채/자기자본)의 역수\n",
    "        bch_rate = sil_df_q[6] / 100  # 부채비율\n",
    "        bch_rate = round((1 / bch_rate) * 100, 2)\n",
    "\n",
    "        # 4. 수익성 분석 - 매출수익성(당기순이익/매출액) # TODO 매출액 0인 애들은?\n",
    "\n",
    "        dg_bene = sil_df_q[2]\n",
    "        mch = sil_df_q[0]\n",
    "\n",
    "        suyk = round((dg_bene / mch) * 100, 2)\n",
    "\n",
    "        # 5. 성장성 분석 - 순이익성장률(지속성장 가능률)\n",
    "        # (1-배당성향)*자기자본순이익률(ROE)\n",
    "        #    유보율\n",
    "\n",
    "        roe = sil_df_y[5] / 100\n",
    "        ubo = (100 - bd_tend) / 100\n",
    "        grth = round(roe * ubo * 100, 2)\n",
    "\n",
    "        data_arr = np.array([bd_tend, dj_rate, bch_rate, suyk, grth])\n",
    "\n",
    "        return data_arr, nm\n",
    "\n",
    "\n",
    "# -------- 관련 기업 지표 선정(상대적 비율 기준)\n",
    "# 220220 수정\n",
    "# 1) 매개변수 stock_code로 축약\n",
    "# 2) dict 대신 array로 반환, 기업 이름(nm도 반환)\n",
    "def relate_radar_data(stock_code):\n",
    "    label_list = ['배당성향', '유동성', '건전성', '수익성', '성장성']\n",
    "    arr_list = []\n",
    "\n",
    "    # 주식 코드,이름으로 변환\n",
    "\n",
    "    gcode = stock_code\n",
    "\n",
    "    relate_corp = relate_code_crawl(co=gcode)\n",
    "\n",
    "    arr_list = [idv_radar_data(stock_code=stcd) for stcd in relate_corp]\n",
    "    nm_list = [x[1] for x in arr_list if x is not None]\n",
    "    arr_list = [x[0] for x in arr_list if x is not None]\n",
    "\n",
    "    arr_list = np.array(arr_list)\n",
    "\n",
    "    arr_list[:, 0] = (arr_list[:, 0] / arr_list[:, 0].mean()) * 100\n",
    "    arr_list[:, 1] = (arr_list[:, 1] / arr_list[:, 1].mean()) * 100\n",
    "    arr_list[:, 2] = (arr_list[:, 2] / arr_list[:, 2].mean()) * 100\n",
    "    arr_list[:, 3] = (arr_list[:, 3] / arr_list[:, 3].mean()) * 100\n",
    "    arr_list[:, 4] = (arr_list[:, 4] / arr_list[:, 4].mean()) * 100\n",
    "\n",
    "    dict_list = []\n",
    "\n",
    "    for i, nm in enumerate(nm_list):\n",
    "        dic = {}\n",
    "        dic[nm] = arr_list[i, :].tolist()\n",
    "        dict_list.append(dic)\n",
    "\n",
    "    return label_list, dict_list\n",
    "\n",
    "\n",
    "# -------- 관련 기업 지표 선정(원본)\n",
    "\n",
    "# def relate_radar_data(yh_code=None, corp_name=None, stock_code=None):\n",
    "#     label_list=['배당성향', '유동성', '건전성', '수익성', '성장성']\n",
    "#     dict_list = []\n",
    "#\n",
    "#     # 주식 코드로 변환\n",
    "#     gcode = 0\n",
    "#     if yh_code != None:\n",
    "#         gcode = yh_code_to_fn_gicode(yh_code)\n",
    "#     elif corp_name != None:\n",
    "#         gcode = nm_to_fn_gicode(corp_name)\n",
    "#     elif stock_code != None:\n",
    "#         gcode = stock_code\n",
    "#\n",
    "#     relate_corp = relate_code_crawl(co=gcode)\n",
    "#\n",
    "#     dict_list = [idv_radar_data(stock_code=stcd) for stcd in relate_corp]\n",
    "#\n",
    "#     dict_list = [x for x in dict_list if x is not None]\n",
    "#\n",
    "#\n",
    "#     return label_list, dict_list\n",
    "\n",
    "\n",
    "#                   ==============\n",
    "#                       시각화\n",
    "#                   ==============\n",
    "\n",
    "# -------- 매출, 당기순이익 추이 그래프\n",
    "# 220220 수정\n",
    "# 1) 매개변수 stock_code로 축약\n",
    "# 2) 크롤링한 데이터는 list로 받아오므로 kind 없애고 직접 인덱스 처리\n",
    "\n",
    "def mch_dg(stock_code):\n",
    "    gcode = stock_code\n",
    "    nm = stc_code_to_nm(stock_code)\n",
    "\n",
    "    bs_df = bs_craw(stock_code=gcode)[0]\n",
    "    label_list = bs_df.columns[1:6].tolist()  # 네 분기 + 전년동기\n",
    "    mch_list = bs_df.loc[0, label_list].tolist()  # 매출액\n",
    "    dg_list = bs_df.loc[15, label_list].tolist()  # 당기순이익\n",
    "\n",
    "    return label_list, mch_list, dg_list\n",
    "\n",
    "\n",
    "def icon_selection(index_array):\n",
    "    res=[]\n",
    "    for idx in index_array:\n",
    "        if 3<idx :\n",
    "            res.append(\"CLEAR_DAY\")\n",
    "        elif ( 1.2<idx and idx<=3 ):\n",
    "            res.append(\"PARTLY_CLOUDY_DAY\")\n",
    "        elif ( 0.8<idx and idx<=1.2 ):\n",
    "            res.append(\"CLOUDY\")\n",
    "        elif ( 0<idx and idx<=0.8 ):\n",
    "            res.append(\"RAIN\")\n",
    "        else:\n",
    "            res.append(\"SNOW\")\n",
    "\n",
    "    return res\n",
    "\n",
    "def foreign_giguan(index_array):\n",
    "    res = []\n",
    "    for idx in index_array:\n",
    "        if idx >=0:\n",
    "            res.append(\"CLEAR_DAY\")\n",
    "        else:\n",
    "            res.append(\"RAIN\")\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "#                      데이터\n",
    "# ====================================================\n",
    "\n",
    "# -------- 병합 파일 불러오기\n",
    "com_df=pd.read_csv('com_df.csv',\n",
    "                   dtype={'stock_code': 'str', '표준코드': 'str', '단축코드': 'str', 'stock_code_ori':'str'},\n",
    "                   parse_dates=['listed_date', '상장일'])\n",
    "\n",
    "\n",
    "\n",
    "# -------- 뉴스 크롤링\n",
    "def news_crawl(gi):\n",
    "\n",
    "\n",
    "    tot_list = []\n",
    "\n",
    "    for p in range(1):\n",
    "        # 뉴스 기사 모인 페이지\n",
    "        url = 'https://m.stock.naver.com/domestic/stock/' + str(gi) + '/news/title'  # https://m.stock.naver.com/domestic/stock/003550/total\n",
    "        #F12누르면 나오는 네트워크상에서 찾아온 경로\n",
    "        #https://m.stock.naver.com/api/news/stock/005930?pageSize=20&page=1&searchMethod=title_entity_id.basic\n",
    "        url = \"https://m.stock.naver.com/api/news/stock/\"+str(gi)+\"?pageSize=5&searchMethod=title_entity_id.basic&page=1\"\n",
    "        res = requests.get(url)\n",
    "\n",
    "        news_list = json.loads(res.text)\n",
    "        #페이지에서 가져온 전체 뉴스기사를 for문으로 분리\n",
    "        #print(news_list[0])\n",
    "        for i, news in enumerate(news_list) :\n",
    "            #신문사 id\n",
    "            a=news['items'][0]['officeId']\n",
    "            #기사 id\n",
    "            b=news['items'][0]['articleId']\n",
    "            list = []\n",
    "            list.append(news['items'][0]['officeName']) #신문사\n",
    "            list.append(news['items'][0]['datetime'][:8]) #날짜\n",
    "            list.append(news['items'][0]['title'].replace('&quot;','\\\"')) #제목\n",
    "            list.append(news['items'][0]['imageOriginLink']) #이미지\n",
    "            list.append(news['items'][0]['body'].replace('&quot;','\\\"')) # 기사 내용\n",
    "            list.append('https://m.stock.naver.com/domestic/stock/005930/news/view/'+str(a)+'/'+str(b)) #기사 url\n",
    "            tot_list.append(list)\n",
    "\n",
    "    news_df = pd.DataFrame(data=tot_list, columns=['offname','rdate','title','imgsrc','content','url'])\n",
    "    news_df['title'] = news_df['title'].str.replace('&amp;', '&')\n",
    "    news_df['content'] = news_df['content'].str.replace('&amp;', '&')\n",
    "\n",
    "    #news_df['title'] = [re.sub('[^A-Za-z0-9가-힣]', '' ,s) for s in news_df['title']]\n",
    "\n",
    "\n",
    "    #news_df.to_csv('css.csv',index=False)\n",
    "    return news_df\n",
    "\n",
    "#co-종목코드\n",
    "def relate_code_crawl(co):\n",
    "    #연관 종목코드 있는 페이지 불러오기\n",
    "    url='https://finance.naver.com/item/main.naver?code='+str(co)\n",
    "    page=pd.read_html(url,encoding='CP949')\n",
    "    #연관 종목명과 종목코드 뽑아내기(code_list[0]은 '종목명'이어서 제외)\n",
    "    code_list=page[4].columns.tolist()\n",
    "    code_list=code_list[1:]\n",
    "    #종목코드 리스트 반환\n",
    "    codes=[]\n",
    "    for word in (code_list):\n",
    "        codes.append(word[-6:])\n",
    "    #print(codes)\n",
    "    return codes\n",
    "\n",
    "\n",
    "# def before_1w_kospi(date):\n",
    "#     before1w=date-timedelta(days=7)\n",
    "#     return fdr.DataReader('KS11',before1w)[['Close']]#, fdr.DataReader('KQ11',before1w)\n",
    "\n",
    "def invest_opinion(gcode):\n",
    "    url='https://finance.naver.com/item/coinfo.naver?code='+str(gcode)\n",
    "    page=pd.read_html(url,encoding='CP949')\n",
    "    try:\n",
    "        a,b=page[3][1].tolist()[0][:4].split('.')\n",
    "        return ((int(a)+int(b)/100)/5)*100 #의견 점수 구한 후 백분율로 다시 변환\n",
    "    except ValueError:\n",
    "        return 0.1\n",
    "#최상현 함수\n",
    "def crawl_ifrs(gcode):\n",
    "    url = \"http://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?pGB=1&gicode=A\" + gcode + \"&cID=&MenuYn=Y&ReportGB=&NewMenuID=11&stkGb=701\"\n",
    "    table_list = pd.read_html(url, encoding='UTF-8')\n",
    "\n",
    "    ifrs = table_list[10]\n",
    "\n",
    "    ifrs = ifrs.fillna('9999999999')\n",
    "    for i in range(1, 5):\n",
    "        ifrs.iloc[:, i] = ifrs.iloc[:, i].apply(lambda x: format(float(x), ','))\n",
    "\n",
    "    ifrs = pd.concat([ifrs['IFRS(연결)'], ifrs['Annual']], axis=1)\n",
    "    ifrs = ifrs.astype(str)\n",
    "    for i in range(1, 5):\n",
    "        ifrs.iloc[:12, i] = ifrs.iloc[:12, i].apply(lambda x: x[:-2])\n",
    "        ifrs.iloc[18:21, i] = ifrs.iloc[18:21, i].apply(lambda x: x[:-2])\n",
    "        ifrs.iloc[23:24, i] = ifrs.iloc[23:24, i].apply(lambda x: x[:-2])\n",
    "    ifrs = ifrs.replace(['9,999,999,999', '9,999,999,999.0'], ['-', '-'])\n",
    "    ifrs.rename(columns={'IFRS(연결)': ''}, inplace=True)\n",
    "    ifrs = ifrs.to_html(justify=\"right\", index=False, classes=\"table\")\n",
    "    ifrs = ifrs.replace('border=\"1\"', 'border=\"0\"')\n",
    "    pd.options.display.float_format = '{:,.0f}'.format\n",
    "    ifrs = ifrs.replace('<td>', '<td align=\"right\">')\n",
    "    ifrs = ifrs.replace('<th>', '<th style=\"text-align: right;\">')\n",
    "    ifrs = ifrs.replace('halign=\"left\"', 'style=\"text-align: center;\"')\n",
    "    ifrs = ifrs.replace('class =\"dataframe table\"', 'class =\"dataframe table\" style = \"table-layout:fixed;word-break:break-all;\"')\n",
    "\n",
    "\n",
    "    return (ifrs)\n",
    "\n",
    "def ori_code(yh_code):\n",
    "    origin_stock=com_df[com_df['yh_code']==yh_code]['stock_code_ori'].values[0]\n",
    "    return origin_stock\n",
    "\n",
    "\n",
    "\n",
    "# 아리마 모델\n",
    "def stock_predict(code,ptype):\n",
    "    data = stock.get_market_ohlcv_by_date(fromdate=\"20220101\", todate=\"20220222\", ticker=str(code))\n",
    "    print(data.head())\n",
    "    data=data[[ptype]]\n",
    "    y_train=data\n",
    "    y_test=data\n",
    "    kpss_diffs = ndiffs(y_train, alpha=0.05, test='kpss', max_d=6)\n",
    "    adf_diffs = ndiffs(y_train, alpha=0.05, test='adf', max_d=6)\n",
    "    n_diffs = max(adf_diffs, kpss_diffs)\n",
    "\n",
    "    print(f\"추정된 차수 d = {n_diffs}\")\n",
    "    model=pm.auto_arima(y_train,d=n_diffs,seasonal=False,trace=True)\n",
    "    model.fit(y_train)\n",
    "    print(model.summary())\n",
    "    def forecast_one_step():\n",
    "        fc, conf_int = model.predict(n_periods=1 # 한 스텝씩!\n",
    "            , return_conf_int=True)              # 신뢰구간 출력\n",
    "        return (\n",
    "            fc.tolist()[0],\n",
    "            np.asarray(conf_int).tolist()[0]\n",
    "        )\n",
    "    forecasts = []\n",
    "    y_pred = []\n",
    "    pred_upper = []\n",
    "    pred_lower = []\n",
    "\n",
    "    for new_ob in y_test[ptype]:\n",
    "\n",
    "        fc, conf = forecast_one_step()\n",
    "        y_pred.append(int(fc))\n",
    "        pred_upper.append(conf[1])\n",
    "        pred_lower.append(conf[0])\n",
    "\n",
    "        ## 모형 업데이트 !!\n",
    "        model.update(new_ob)\n",
    "    fc_last = model.predict(n_periods=1 # 한 스텝씩!\n",
    "            )\n",
    "    df=pd.DataFrame({\"test\": y_test[ptype], \"pred\": y_pred})\n",
    "    print(df.tail())\n",
    "    def MAE(y_test, y_pred):\n",
    "        return np.mean(np.abs((df['test']-df['pred'])/df['test']))*100\n",
    "    mae=np.round(MAE(y_test, y_pred).astype('float'),4)\n",
    "    print(f\"MAE: {MAE(y_test, y_pred):.3f}\")\n",
    "    price_list=[]\n",
    "    return int(fc_last),mae\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5baf623-bb9a-4145-8af1-d42fc4c93d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9113fe-7250-49ad-becf-82b5e383bc9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "html5lib not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15236/1943717301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?pGB=1&gicode=AA352820&cID=&MenuYn=Y&ReportGB=&NewMenuID=11&stkGb=701\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtable_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mifrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ai\\pythonproject\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ai\\pythonproject\\venv\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[0;32m   1096\u001b[0m     \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m     return _parse(\n\u001b[0m\u001b[0;32m   1099\u001b[0m         \u001b[0mflavor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflavor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \u001b[0mio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ai\\pythonproject\\venv\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[0mretained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mflav\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflavor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 902\u001b[1;33m         \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    903\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompiled_match\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplayed_only\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ai\\pythonproject\\venv\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parser_dispatch\u001b[1;34m(flavor)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflavor\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"bs4\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html5lib\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_HAS_HTML5LIB\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"html5lib not found, please install it\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_HAS_BS4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"BeautifulSoup4 (bs4) not found, please install it\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: html5lib not found, please install it"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"http://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?pGB=1&gicode=AA352820&cID=&MenuYn=Y&ReportGB=&NewMenuID=11&stkGb=701\"\n",
    "table_list = pd.read_html(url, encoding='UTF-8')\n",
    "\n",
    "ifrs = table_list[10]\n",
    "\n",
    "ifrs = ifrs.fillna('9999999999')\n",
    "for i in range(1, 5):\n",
    "    ifrs.iloc[:, i] = ifrs.iloc[:, i].apply(lambda x: format(float(x), ','))\n",
    "\n",
    "ifrs = pd.concat([ifrs['IFRS(연결)'], ifrs['Annual']], axis=1)\n",
    "ifrs = ifrs.astype(str)\n",
    "for i in range(1, 5):\n",
    "    ifrs.iloc[:12, i] = ifrs.iloc[:12, i].apply(lambda x: x[:-2])\n",
    "    ifrs.iloc[18:21, i] = ifrs.iloc[18:21, i].apply(lambda x: x[:-2])\n",
    "    ifrs.iloc[23:24, i] = ifrs.iloc[23:24, i].apply(lambda x: x[:-2])\n",
    "ifrs = ifrs.replace(['9,999,999,999', '9,999,999,999.0'], ['-', '-'])\n",
    "ifrs.rename(columns={'IFRS(연결)': ''}, inplace=True)\n",
    "ifrs = ifrs.to_html(justify=\"right\", index=False, classes=\"table\")\n",
    "ifrs = ifrs.replace('border=\"1\"', 'border=\"0\"')\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "ifrs = ifrs.replace('<td>', '<td align=\"right\">')\n",
    "ifrs = ifrs.replace('<th>', '<th style=\"text-align: right;\">')\n",
    "ifrs = ifrs.replace('halign=\"left\"', 'style=\"text-align: center;\"')\n",
    "ifrs = ifrs.replace('class =\"dataframe table\"', 'class =\"dataframe table\" style = \"table-layout:fixed;word-break:break-all;\"')\n",
    "\n",
    "\n",
    "# return (ifrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e5629-5747-4c9c-96ac-6ed12c68896a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "163bf093-cd0e-4819-8095-238c73cfd237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(' N/A(IFRS)'))\n",
    "type(' N/A(IFRS)')==str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443dd0d-c941-4fc4-b116-45c1bd7bd258",
   "metadata": {},
   "outputs": [],
   "source": [
    "type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07e5ae-b7fc-4b17-b7eb-3b2ac31601ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230e029d-2b2b-4a92-a9c6-608124e51732",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    url = \"http://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?pGB=1&gicode=A\" + gcode + \"&cID=&MenuYn=Y&ReportGB=&NewMenuID=11&stkGb=701\"\n",
    "    table_list = pd.read_html(url, encoding='UTF-8')\n",
    "\n",
    "    ifrs = table_list[10]\n",
    "\n",
    "    ifrs = ifrs.fillna('9999999999')\n",
    "    for i in range(1, 5):\n",
    "        ifrs.iloc[:, i] = ifrs.iloc[:, i].apply(lambda x: format(float(x), ','))\n",
    "\n",
    "    ifrs = pd.concat([ifrs['IFRS(연결)'], ifrs['Annual']], axis=1)\n",
    "    ifrs = ifrs.astype(str)\n",
    "    for i in range(1, 5):\n",
    "        ifrs.iloc[:12, i] = ifrs.iloc[:12, i].apply(lambda x: x[:-2])\n",
    "        ifrs.iloc[18:21, i] = ifrs.iloc[18:21, i].apply(lambda x: x[:-2])\n",
    "        ifrs.iloc[23:24, i] = ifrs.iloc[23:24, i].apply(lambda x: x[:-2])\n",
    "    ifrs = ifrs.replace(['9,999,999,999', '9,999,999,999.0'], ['-', '-'])\n",
    "    ifrs.rename(columns={'IFRS(연결)': ''}, inplace=True)\n",
    "    ifrs = ifrs.to_html(justify=\"right\", index=False, classes=\"table\")\n",
    "    ifrs = ifrs.replace('border=\"1\"', 'border=\"0\"')\n",
    "    pd.options.display.float_format = '{:,.0f}'.format\n",
    "    ifrs = ifrs.replace('<td>', '<td align=\"right\">')\n",
    "    ifrs = ifrs.replace('<th>', '<th style=\"text-align: right;\">')\n",
    "    ifrs = ifrs.replace('halign=\"left\"', 'style=\"text-align: center;\"')\n",
    "    ifrs = ifrs.replace('class =\"dataframe table\"', 'class =\"dataframe table\" style = \"table-layout:fixed;word-break:break-all;\"')\n",
    "\n",
    "\n",
    "    return (ifrs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
